{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9732149a",
   "metadata": {},
   "source": [
    "# PROYECTO PLN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421cbdb",
   "metadata": {},
   "source": [
    "## Paula Cabrera, Bartolomé Sabater, Andrea Cardete y Alberto Belmonte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e6012",
   "metadata": {},
   "source": [
    "### Importamos los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75255db6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sem_eval_train_es.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msem_eval_train_es.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df2\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msem_eval_test_grupo_11.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m df2\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sem_eval_train_es.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sem_eval_train_es.csv')\n",
    "df2=pd.read_csv('sem_eval_test_grupo_11.csv')\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a1123",
   "metadata": {},
   "source": [
    "### Eliminamos las filas del dataframe donde el Tweet no tiene sentimientos, es decir, todas las columnas referidas a sentimientos tienen un valor de False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e6a10b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Es-01643</td>\n",
       "      <td>@aliciaenp Ajajjaa somos del clan twitteras pe...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Es-05142</td>\n",
       "      <td>@AwadaNai la mala suerte del gato fichame la c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Es-05379</td>\n",
       "      <td>@audiomano A mí tampoco me agrado mucho eso. E...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Es-00208</td>\n",
       "      <td>Para llevar a los bebes de un lugar a otro deb...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Es-01385</td>\n",
       "      <td>@DalasReview me encanta la terrible hipocresia...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>2018-Es-06340</td>\n",
       "      <td>Ahorita quisiera que mi preocupación más grand...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>2018-Es-00439</td>\n",
       "      <td>El mayor criminal del país diciéndole “delincu...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>2018-Es-04919</td>\n",
       "      <td>Mi prima de 4 años se ha enfadado conmigo porq...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>2018-Es-02703</td>\n",
       "      <td>@lennycia Jajaja...  Ya seee</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>2018-Es-02680</td>\n",
       "      <td>Quiero abrazar. Quiero querer. Me hace falta e...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3397 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              Tweet  anger  \\\n",
       "0     2018-Es-01643  @aliciaenp Ajajjaa somos del clan twitteras pe...  False   \n",
       "1     2018-Es-05142  @AwadaNai la mala suerte del gato fichame la c...  False   \n",
       "2     2018-Es-05379  @audiomano A mí tampoco me agrado mucho eso. E...   True   \n",
       "3     2018-Es-00208  Para llevar a los bebes de un lugar a otro deb...  False   \n",
       "4     2018-Es-01385  @DalasReview me encanta la terrible hipocresia...   True   \n",
       "...             ...                                                ...    ...   \n",
       "3556  2018-Es-06340  Ahorita quisiera que mi preocupación más grand...  False   \n",
       "3557  2018-Es-00439  El mayor criminal del país diciéndole “delincu...   True   \n",
       "3558  2018-Es-04919  Mi prima de 4 años se ha enfadado conmigo porq...   True   \n",
       "3559  2018-Es-02703                      @lennycia Jajaja...  Ya seee   False   \n",
       "3560  2018-Es-02680  Quiero abrazar. Quiero querer. Me hace falta e...  False   \n",
       "\n",
       "      anticipation  disgust   fear    joy   love  optimism  pessimism  \\\n",
       "0            False    False  False   True  False     False      False   \n",
       "1            False    False   True  False  False     False       True   \n",
       "2            False    False  False  False  False     False      False   \n",
       "3            False    False  False   True  False     False      False   \n",
       "4            False     True  False  False  False     False      False   \n",
       "...            ...      ...    ...    ...    ...       ...        ...   \n",
       "3556         False    False   True  False  False     False       True   \n",
       "3557         False     True  False  False  False     False      False   \n",
       "3558         False    False  False  False  False     False      False   \n",
       "3559         False    False  False   True  False     False      False   \n",
       "3560         False    False  False  False   True     False      False   \n",
       "\n",
       "      sadness  surprise  trust  \n",
       "0       False     False  False  \n",
       "1       False     False  False  \n",
       "2       False     False  False  \n",
       "3       False     False  False  \n",
       "4       False     False  False  \n",
       "...       ...       ...    ...  \n",
       "3556     True     False  False  \n",
       "3557    False     False  False  \n",
       "3558    False      True  False  \n",
       "3559    False     False  False  \n",
       "3560     True     False  False  \n",
       "\n",
       "[3397 rows x 13 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.select_dtypes(include='bool')\n",
    "for i in x.index: # filas\n",
    "    y = False\n",
    "    for j in ['anger','anticipation','disgust','fear','joy','love','optimism',\n",
    "              'pessimism','sadness','surprise','trust']: # Recorremos cada sentimiento\n",
    "        if x[j][i]:\n",
    "            y = True\n",
    "        elif not y:\n",
    "            if j == 'trust':\n",
    "                df = df.drop(i, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20145c",
   "metadata": {},
   "source": [
    "### Obtenemos los valores de los sentimientos y los guardamos en la variable categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ab4cd536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love',\n",
       "       'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories=x.columns.values\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebacbda",
   "metadata": {},
   "source": [
    "### Realizamos un recuento de las veces que sale cada sentimiento a modo informativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0f81bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 1155), ('anticipation', 415), ('disgust', 521), ('fear', 373), ('joy', 1087), ('love', 261), ('optimism', 378), ('pessimism', 578), ('sadness', 845), ('surprise', 169), ('trust', 175)]\n"
     ]
    }
   ],
   "source": [
    "count = list() # Esto es la lista con el recuento de cada sentimiento\n",
    "for i in ['anger','anticipation','disgust','fear','joy','love','optimism','pessimism','sadness','surprise','trust']: # Recorremos cada sentimiento\n",
    "    sum = 0\n",
    "    for j in df.index: # filas\n",
    "        if df[i][j]:\n",
    "            sum += 1\n",
    "    count.append((i,sum)) # Guardamos la suma\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283563c0",
   "metadata": {},
   "source": [
    "### Importamos todas las librerías que nos pueden ser útiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dd39fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import resample\n",
    "\n",
    "import spacy\n",
    "\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation \n",
    "from gensim.models import LdaModel\n",
    "import gensim\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from textacy.extract import keyterms as kt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb050d2",
   "metadata": {},
   "source": [
    "### Creamos el modelo de limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d2f6b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de stop-words específicos de nuestro corpus (aproximación)\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "pattern2 = re.compile('[{}]'.format(re.escape(string.punctuation))) #elimina símbolos de puntuación\n",
    "\n",
    "def clean_text(text, lemas=False):\n",
    "    \"\"\"Limpiamos las menciones y URL del texto. Luego convertimos en tokens\n",
    "    y eliminamos signos de puntuación.\n",
    "    Si lemas=True extraemos el lema, si no dejamos en minúsculas solamente.\n",
    "    Como salida volvemos a convertir los tokens en cadena de texto\"\"\"\n",
    "    text = re.sub(r'@[\\w_]+|https?://[\\w_./]+', '', text) #elimina menciones y URL\n",
    "    tokens = nlp(text)\n",
    "    tokens = [tok.lemma_.lower() if lemas else tok.lower_ for tok in tokens if not tok.is_punct]\n",
    "    filtered_tokens = [pattern2.sub('', tok) for tok in tokens if len(tok)>2]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98660d",
   "metadata": {},
   "source": [
    "### Aplicamos la limpieza a los datos, lo hacemos con los Tweets limpios y con los lemas, y los añadimos a nuestro dataframe de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "571d8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"limpio\"]=df['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "94df1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemas\"]=df['Tweet'].apply(clean_text, lemas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee278f",
   "metadata": {},
   "source": [
    "### Seleccionamos las columnas referidas a sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "889ab7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3397 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger  anticipation  disgust   fear    joy   love  optimism  pessimism  \\\n",
       "0     False         False    False  False   True  False     False      False   \n",
       "1     False         False    False   True  False  False     False       True   \n",
       "2      True         False    False  False  False  False     False      False   \n",
       "3     False         False    False  False   True  False     False      False   \n",
       "4      True         False     True  False  False  False     False      False   \n",
       "...     ...           ...      ...    ...    ...    ...       ...        ...   \n",
       "3556  False         False    False   True  False  False     False       True   \n",
       "3557   True         False     True  False  False  False     False      False   \n",
       "3558   True         False    False  False  False  False     False      False   \n",
       "3559  False         False    False  False   True  False     False      False   \n",
       "3560  False         False    False  False  False   True     False      False   \n",
       "\n",
       "      sadness  surprise  trust  \n",
       "0       False     False  False  \n",
       "1       False     False  False  \n",
       "2       False     False  False  \n",
       "3       False     False  False  \n",
       "4       False     False  False  \n",
       "...       ...       ...    ...  \n",
       "3556     True     False  False  \n",
       "3557    False     False  False  \n",
       "3558    False      True  False  \n",
       "3559    False     False  False  \n",
       "3560     True     False  False  \n",
       "\n",
       "[3397 rows x 11 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.select_dtypes(include='bool')\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc517a0",
   "metadata": {},
   "source": [
    "### Dividimos los datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "156c1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "# Asignamos un 70% a training y un 30% a test\n",
    "X_train, X_test, y_train, y_test, X_train_lema, X_test_lema = train_test_split(df['limpio'], \n",
    "                                                    y,\n",
    "                                                    df['lemas'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efd5fb",
   "metadata": {},
   "source": [
    "### Extraemos las características mediante BoW, creamos los modelos, los entrenamos y realizamos las predicciones para comprarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9bc5cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2377, 6444)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# aprendemos el modelo CountVectorizer sobre el conjunto de train\n",
    "vect1 = CountVectorizer()\n",
    "\n",
    "X_train_vectorized1 = vect1.fit_transform(X_train)\n",
    "print(X_train_vectorized1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e0292c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   solver='liblinear'))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODELO BOW - LR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "modelLR1 = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "model1 = MultiOutputClassifier(estimator=modelLR)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "model1.fit(X_train_vectorized1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "99042429",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_train = model1.predict(X_train_vectorized1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3da03ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.8754732856541859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Exactitud: ', accuracy_score(y_train, prediccion_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "91d3fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 6444)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectorized = vect1.transform(X_test)\n",
    "X_test_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a2f8f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = model1.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d46fbf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.18529411764705883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63       337\n",
      "           1       0.33      0.41      0.37       113\n",
      "           2       0.39      0.34      0.36       158\n",
      "           3       0.72      0.63      0.67       116\n",
      "           4       0.70      0.60      0.65       324\n",
      "           5       0.40      0.39      0.39        77\n",
      "           6       0.39      0.28      0.33       126\n",
      "           7       0.35      0.39      0.37       166\n",
      "           8       0.57      0.49      0.53       249\n",
      "           9       0.29      0.30      0.29        47\n",
      "          10       0.20      0.13      0.16        54\n",
      "\n",
      "   micro avg       0.52      0.48      0.50      1767\n",
      "   macro avg       0.45      0.42      0.43      1767\n",
      "weighted avg       0.52      0.48      0.50      1767\n",
      " samples avg       0.50      0.51      0.48      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e990a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.1450980392156863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.42      0.52       337\n",
      "           1       0.38      0.03      0.05       113\n",
      "           2       0.56      0.06      0.10       158\n",
      "           3       0.79      0.13      0.22       116\n",
      "           4       0.77      0.44      0.56       324\n",
      "           5       1.00      0.04      0.08        77\n",
      "           6       0.75      0.02      0.05       126\n",
      "           7       0.42      0.05      0.09       166\n",
      "           8       0.74      0.26      0.38       249\n",
      "           9       0.00      0.00      0.00        47\n",
      "          10       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.71      0.22      0.34      1767\n",
      "   macro avg       0.55      0.13      0.19      1767\n",
      "weighted avg       0.64      0.22      0.30      1767\n",
      " samples avg       0.34      0.26      0.28      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-NB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB=MultinomialNB()\n",
    "NB = MultiOutputClassifier(estimator=NB)\n",
    "#Entrenem el model\n",
    "NB.fit(X_train_vectorized1, y_train)\n",
    "\n",
    "#Realitzem les prediccions\n",
    "pred=NB.predict(X_test_vectorized)\n",
    "\n",
    "print('Exactitud: ', accuracy_score(y_test, pred))\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b444f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.15098039215686274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       337\n",
      "           1       0.24      0.47      0.32       113\n",
      "           2       0.35      0.32      0.33       158\n",
      "           3       0.67      0.57      0.62       116\n",
      "           4       0.65      0.60      0.62       324\n",
      "           5       0.36      0.42      0.38        77\n",
      "           6       0.37      0.24      0.29       126\n",
      "           7       0.27      0.30      0.29       166\n",
      "           8       0.53      0.45      0.48       249\n",
      "           9       0.24      0.36      0.29        47\n",
      "          10       0.22      0.15      0.18        54\n",
      "\n",
      "   micro avg       0.46      0.45      0.46      1767\n",
      "   macro avg       0.41      0.40      0.40      1767\n",
      "weighted avg       0.48      0.45      0.46      1767\n",
      " samples avg       0.45      0.48      0.43      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-SVM\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SVM=SGDClassifier(loss='hinge', max_iter=10000, tol=1e-5, class_weight='balanced')\n",
    "SVM = MultiOutputClassifier(estimator=SVM)\n",
    "\n",
    "#Entrenem el model\n",
    "SVM.fit(X_train_vectorized1, y_train)\n",
    "\n",
    "#Realitzem les prediccions\n",
    "pred=SVM.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a8a90",
   "metadata": {},
   "source": [
    "### Extraemos las características mediante TF-IDF, creamos los modelos, los entrenamos y realizamos las predicciones para comprarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3195c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64       337\n",
      "           1       0.29      0.44      0.35       113\n",
      "           2       0.33      0.39      0.36       158\n",
      "           3       0.69      0.61      0.65       116\n",
      "           4       0.68      0.64      0.66       324\n",
      "           5       0.37      0.40      0.39        77\n",
      "           6       0.34      0.33      0.34       126\n",
      "           7       0.34      0.49      0.40       166\n",
      "           8       0.53      0.53      0.53       249\n",
      "           9       0.31      0.32      0.31        47\n",
      "          10       0.20      0.17      0.18        54\n",
      "\n",
      "   micro avg       0.48      0.52      0.50      1767\n",
      "   macro avg       0.43      0.45      0.44      1767\n",
      "weighted avg       0.50      0.52      0.51      1767\n",
      " samples avg       0.49      0.55      0.49      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "modelo = make_pipeline(vect, model)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6eb481b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.04803921568627451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.12      0.21       337\n",
      "           1       0.00      0.00      0.00       113\n",
      "           2       0.00      0.00      0.00       158\n",
      "           3       0.00      0.00      0.00       116\n",
      "           4       0.95      0.13      0.22       324\n",
      "           5       0.00      0.00      0.00        77\n",
      "           6       0.00      0.00      0.00       126\n",
      "           7       0.00      0.00      0.00       166\n",
      "           8       0.92      0.04      0.08       249\n",
      "           9       0.00      0.00      0.00        47\n",
      "          10       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.88      0.05      0.10      1767\n",
      "   macro avg       0.24      0.03      0.05      1767\n",
      "weighted avg       0.46      0.05      0.09      1767\n",
      " samples avg       0.09      0.07      0.08      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = make_pipeline(vect, NB)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7f007ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.1676470588235294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61       337\n",
      "           1       0.33      0.39      0.36       113\n",
      "           2       0.33      0.33      0.33       158\n",
      "           3       0.68      0.60      0.64       116\n",
      "           4       0.67      0.60      0.64       324\n",
      "           5       0.37      0.38      0.37        77\n",
      "           6       0.29      0.20      0.24       126\n",
      "           7       0.32      0.36      0.34       166\n",
      "           8       0.51      0.49      0.50       249\n",
      "           9       0.31      0.34      0.32        47\n",
      "          10       0.22      0.13      0.16        54\n",
      "\n",
      "   micro avg       0.49      0.47      0.48      1767\n",
      "   macro avg       0.42      0.40      0.41      1767\n",
      "weighted avg       0.49      0.47      0.48      1767\n",
      " samples avg       0.48      0.50      0.46      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = make_pipeline(vect, SVM)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fded011",
   "metadata": {},
   "source": [
    "### Hacemos los mismo pero con los lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7224170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2377, 5337)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizamos\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train_lema)\n",
    "X_test_vectorized = vect.transform(X_test_lema)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "98d88b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.1715686274509804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60       337\n",
      "           1       0.32      0.40      0.35       113\n",
      "           2       0.33      0.32      0.33       158\n",
      "           3       0.70      0.62      0.66       116\n",
      "           4       0.69      0.63      0.66       324\n",
      "           5       0.43      0.43      0.43        77\n",
      "           6       0.38      0.31      0.34       126\n",
      "           7       0.33      0.42      0.37       166\n",
      "           8       0.55      0.51      0.53       249\n",
      "           9       0.23      0.28      0.25        47\n",
      "          10       0.20      0.17      0.18        54\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      1767\n",
      "   macro avg       0.43      0.43      0.43      1767\n",
      "weighted avg       0.51      0.49      0.50      1767\n",
      " samples avg       0.48      0.51      0.46      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-LR\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "prediccion = model.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a634b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.1411764705882353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.41      0.52       337\n",
      "           1       0.50      0.02      0.03       113\n",
      "           2       0.58      0.07      0.12       158\n",
      "           3       0.73      0.09      0.17       116\n",
      "           4       0.79      0.36      0.50       324\n",
      "           5       1.00      0.06      0.12        77\n",
      "           6       0.50      0.01      0.02       126\n",
      "           7       0.39      0.04      0.08       166\n",
      "           8       0.72      0.22      0.34       249\n",
      "           9       0.00      0.00      0.00        47\n",
      "          10       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.72      0.20      0.31      1767\n",
      "   macro avg       0.54      0.12      0.17      1767\n",
      "weighted avg       0.63      0.20      0.28      1767\n",
      " samples avg       0.31      0.24      0.26      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-NB\n",
    "NB.fit(X_train_vectorized, y_train)\n",
    "prediccion = NB.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81835507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.14411764705882352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       337\n",
      "           1       0.27      0.35      0.30       113\n",
      "           2       0.27      0.38      0.32       158\n",
      "           3       0.67      0.55      0.61       116\n",
      "           4       0.66      0.59      0.62       324\n",
      "           5       0.38      0.29      0.33        77\n",
      "           6       0.32      0.32      0.32       126\n",
      "           7       0.32      0.43      0.36       166\n",
      "           8       0.47      0.56      0.51       249\n",
      "           9       0.17      0.26      0.20        47\n",
      "          10       0.17      0.13      0.15        54\n",
      "\n",
      "   micro avg       0.44      0.48      0.46      1767\n",
      "   macro avg       0.39      0.40      0.39      1767\n",
      "weighted avg       0.46      0.48      0.47      1767\n",
      " samples avg       0.44      0.50      0.44      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-SVM\n",
    "SVM.fit(X_train_vectorized, y_train)\n",
    "prediccion = SVM.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f942376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2377, 5337)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizamos\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train_lema)\n",
    "X_test_vectorized = vect.transform(X_test_lema)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5536a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.15588235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.61       337\n",
      "           1       0.27      0.46      0.34       113\n",
      "           2       0.30      0.42      0.35       158\n",
      "           3       0.67      0.65      0.66       116\n",
      "           4       0.67      0.65      0.66       324\n",
      "           5       0.36      0.45      0.40        77\n",
      "           6       0.32      0.37      0.34       126\n",
      "           7       0.30      0.50      0.37       166\n",
      "           8       0.50      0.55      0.52       249\n",
      "           9       0.21      0.32      0.25        47\n",
      "          10       0.16      0.17      0.16        54\n",
      "\n",
      "   micro avg       0.44      0.53      0.48      1767\n",
      "   macro avg       0.39      0.47      0.43      1767\n",
      "weighted avg       0.47      0.53      0.50      1767\n",
      " samples avg       0.46      0.56      0.47      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo TFIDF-LR\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "prediccion = model.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d1a76c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.054901960784313725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.13      0.23       337\n",
      "           1       1.00      0.01      0.02       113\n",
      "           2       0.00      0.00      0.00       158\n",
      "           3       0.00      0.00      0.00       116\n",
      "           4       0.96      0.14      0.25       324\n",
      "           5       0.00      0.00      0.00        77\n",
      "           6       0.00      0.00      0.00       126\n",
      "           7       0.00      0.00      0.00       166\n",
      "           8       1.00      0.04      0.08       249\n",
      "           9       0.00      0.00      0.00        47\n",
      "          10       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.91      0.06      0.11      1767\n",
      "   macro avg       0.35      0.03      0.05      1767\n",
      "weighted avg       0.54      0.06      0.10      1767\n",
      " samples avg       0.10      0.08      0.08      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo TFIDF-NB\n",
    "NB.fit(X_train_vectorized, y_train)\n",
    "prediccion = NB.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9231f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.15588235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59       337\n",
      "           1       0.27      0.32      0.29       113\n",
      "           2       0.29      0.32      0.31       158\n",
      "           3       0.63      0.55      0.59       116\n",
      "           4       0.66      0.61      0.63       324\n",
      "           5       0.45      0.38      0.41        77\n",
      "           6       0.31      0.28      0.29       126\n",
      "           7       0.30      0.39      0.34       166\n",
      "           8       0.50      0.51      0.51       249\n",
      "           9       0.17      0.19      0.18        47\n",
      "          10       0.20      0.15      0.17        54\n",
      "\n",
      "   micro avg       0.46      0.47      0.46      1767\n",
      "   macro avg       0.40      0.39      0.39      1767\n",
      "weighted avg       0.47      0.47      0.46      1767\n",
      " samples avg       0.45      0.49      0.44      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo TFIDF-SVM\n",
    "SVM.fit(X_train_vectorized, y_train)\n",
    "prediccion = SVM.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13480e50",
   "metadata": {},
   "source": [
    "### Una vez realizados todos los modelos y comparando su accuracy y sus tablas, decidimos que el mejor modelo entrenado es el LogisticRegression extrayendo las características mediante BoW, por lo que vamos a realizar la predicción de los datos de test mediante este modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58762a1",
   "metadata": {},
   "source": [
    "### Limpiamos los Tweets del dataframe de test proporcionado para, a continuación, realizar la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9d539981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      jaj tan resentido\n",
       "1                                estoy emocionada aaaaah\n",
       "2                        satisfacción por deber cumplido\n",
       "3                considerate afortunada mío hasta ignora\n",
       "4                                                  enojo\n",
       "                             ...                        \n",
       "674                 que nunca vas dejar ponerme nerviosa\n",
       "675                    anon sos terrible cornuda bla etc\n",
       "676           problemas trabajo embarque detenido terror\n",
       "677    nostalgia unas horas lanzamiento oficial secue...\n",
       "678                    anoche estalló vena furia milagro\n",
       "Name: Tweet, Length: 679, dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet=df2['Tweet']\n",
    "limpio=tweet.apply(clean_text)\n",
    "limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1035e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "limpio_vec=vect1.transform(limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8bbe20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(679, 6444)\n",
      "(2377, 6444)\n"
     ]
    }
   ],
   "source": [
    "print(limpio_vec.shape)\n",
    "print(X_train_vectorized1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ca62fae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False,  True],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       [ True, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modelo BoW-LR\n",
    "\n",
    "#Realitzem les prediccions\n",
    "pred=model1.predict(limpio_vec)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "22235615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Es-00074</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Es-02721</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Es-04447</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Es-04392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Es-03765</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2018-Es-00162</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2018-Es-05538</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2018-Es-00430</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2018-Es-02679</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2018-Es-06005</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  anger  anticipation  disgust   fear    joy   love  \\\n",
       "0    2018-Es-00074   True         False     True  False  False  False   \n",
       "1    2018-Es-02721  False         False    False  False   True  False   \n",
       "2    2018-Es-04447  False         False    False  False   True  False   \n",
       "3    2018-Es-04392  False         False    False  False   True  False   \n",
       "4    2018-Es-03765   True          True    False  False  False  False   \n",
       "..             ...    ...           ...      ...    ...    ...    ...   \n",
       "674  2018-Es-00162  False          True    False   True  False  False   \n",
       "675  2018-Es-05538   True         False     True  False  False  False   \n",
       "676  2018-Es-00430  False         False    False   True  False  False   \n",
       "677  2018-Es-02679  False         False    False  False  False  False   \n",
       "678  2018-Es-06005   True         False    False  False  False  False   \n",
       "\n",
       "     optimism  pessimism  sadness  surprise  trust  \n",
       "0       False      False    False     False  False  \n",
       "1       False      False    False     False  False  \n",
       "2       False      False    False     False   True  \n",
       "3       False      False    False     False   True  \n",
       "4       False      False    False     False  False  \n",
       "..        ...        ...      ...       ...    ...  \n",
       "674     False      False    False     False  False  \n",
       "675     False      False    False     False  False  \n",
       "676     False      False    False     False  False  \n",
       "677     False      False     True     False  False  \n",
       "678     False      False    False     False  False  \n",
       "\n",
       "[679 rows x 12 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitivo=pd.concat([df2['ID'], pd.DataFrame(pred,columns=categories)], axis=1)\n",
    "definitivo.iloc[:,1:]=definitivo.iloc[:,1:]==1\n",
    "definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7cc14d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 679 entries, 0 to 678\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ID            679 non-null    object\n",
      " 1   anger         679 non-null    bool  \n",
      " 2   anticipation  679 non-null    bool  \n",
      " 3   disgust       679 non-null    bool  \n",
      " 4   fear          679 non-null    bool  \n",
      " 5   joy           679 non-null    bool  \n",
      " 6   love          679 non-null    bool  \n",
      " 7   optimism      679 non-null    bool  \n",
      " 8   pessimism     679 non-null    bool  \n",
      " 9   sadness       679 non-null    bool  \n",
      " 10  surprise      679 non-null    bool  \n",
      " 11  trust         679 non-null    bool  \n",
      "dtypes: bool(11), object(1)\n",
      "memory usage: 12.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Juntamos los dataframes para obtener el definitivo\n",
    "definitivo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b5630",
   "metadata": {},
   "source": [
    "### Creamos el csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "174b4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitivo.to_csv('C:/Users/1487846/Documents/GCD/TERCERO/SEGUNDO CUATRI/PLN/grupo11.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
