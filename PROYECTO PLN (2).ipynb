{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9732149a",
   "metadata": {},
   "source": [
    "# PROYECTO PLN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e6012",
   "metadata": {},
   "source": [
    "### Importamos los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "75255db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Es-00074</td>\n",
       "      <td>@omardi_cabj jaj tan resentido?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Es-02721</td>\n",
       "      <td>@Camila_Cabello @BrunoMars ESTOY EMOCIONADA AA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Es-04447</td>\n",
       "      <td>La satisfacci√≥n por el deber cumplido‚ù§Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Es-04392</td>\n",
       "      <td>@sthephannym Considerate afortunada. El m√≠o ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Es-03765</td>\n",
       "      <td>Se enojo üòÇüòÇüòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2018-Es-00162</td>\n",
       "      <td>es que nunca vas a dejar de ponerme nerviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2018-Es-05538</td>\n",
       "      <td>@sofiakd anon sos terrible cornuda y bla etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2018-Es-00430</td>\n",
       "      <td>@fredyPaSa @fernansubreal @ChavaFerrer Problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2018-Es-02679</td>\n",
       "      <td>#Nostalgia En unas horas es el lanzamiento ofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2018-Es-06005</td>\n",
       "      <td>Anoche no me estall√≥ la vena de la furia de mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                              Tweet\n",
       "0    2018-Es-00074                    @omardi_cabj jaj tan resentido?\n",
       "1    2018-Es-02721  @Camila_Cabello @BrunoMars ESTOY EMOCIONADA AA...\n",
       "2    2018-Es-04447            La satisfacci√≥n por el deber cumplido‚ù§Ô∏è\n",
       "3    2018-Es-04392  @sthephannym Considerate afortunada. El m√≠o ha...\n",
       "4    2018-Es-03765                                       Se enojo üòÇüòÇüòÇ\n",
       "..             ...                                                ...\n",
       "674  2018-Es-00162       es que nunca vas a dejar de ponerme nerviosa\n",
       "675  2018-Es-05538       @sofiakd anon sos terrible cornuda y bla etc\n",
       "676  2018-Es-00430  @fredyPaSa @fernansubreal @ChavaFerrer Problem...\n",
       "677  2018-Es-02679  #Nostalgia En unas horas es el lanzamiento ofi...\n",
       "678  2018-Es-06005  Anoche no me estall√≥ la vena de la furia de mi...\n",
       "\n",
       "[679 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sem_eval_train_es.csv')\n",
    "df2=pd.read_csv('sem_eval_test_grupo_11.csv')\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a1123",
   "metadata": {},
   "source": [
    "### Eliminamos las filas del dataframe donde el Tweet no tiene sentimientos, es decir, todas las columnas referidas a sentimientos tienen un valor de False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e6a10b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Es-01643</td>\n",
       "      <td>@aliciaenp Ajajjaa somos del clan twitteras pe...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Es-05142</td>\n",
       "      <td>@AwadaNai la mala suerte del gato fichame la c...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Es-05379</td>\n",
       "      <td>@audiomano A m√≠ tampoco me agrado mucho eso. E...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Es-00208</td>\n",
       "      <td>Para llevar a los bebes de un lugar a otro deb...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Es-01385</td>\n",
       "      <td>@DalasReview me encanta la terrible hipocresia...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>2018-Es-06340</td>\n",
       "      <td>Ahorita quisiera que mi preocupaci√≥n m√°s grand...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>2018-Es-00439</td>\n",
       "      <td>El mayor criminal del pa√≠s dici√©ndole ‚Äúdelincu...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>2018-Es-04919</td>\n",
       "      <td>Mi prima de 4 a√±os se ha enfadado conmigo porq...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>2018-Es-02703</td>\n",
       "      <td>@lennycia Jajaja...  Ya seee</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>2018-Es-02680</td>\n",
       "      <td>Quiero abrazar. Quiero querer. Me hace falta e...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3397 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              Tweet  anger  \\\n",
       "0     2018-Es-01643  @aliciaenp Ajajjaa somos del clan twitteras pe...  False   \n",
       "1     2018-Es-05142  @AwadaNai la mala suerte del gato fichame la c...  False   \n",
       "2     2018-Es-05379  @audiomano A m√≠ tampoco me agrado mucho eso. E...   True   \n",
       "3     2018-Es-00208  Para llevar a los bebes de un lugar a otro deb...  False   \n",
       "4     2018-Es-01385  @DalasReview me encanta la terrible hipocresia...   True   \n",
       "...             ...                                                ...    ...   \n",
       "3556  2018-Es-06340  Ahorita quisiera que mi preocupaci√≥n m√°s grand...  False   \n",
       "3557  2018-Es-00439  El mayor criminal del pa√≠s dici√©ndole ‚Äúdelincu...   True   \n",
       "3558  2018-Es-04919  Mi prima de 4 a√±os se ha enfadado conmigo porq...   True   \n",
       "3559  2018-Es-02703                      @lennycia Jajaja...  Ya seee   False   \n",
       "3560  2018-Es-02680  Quiero abrazar. Quiero querer. Me hace falta e...  False   \n",
       "\n",
       "      anticipation  disgust   fear    joy   love  optimism  pessimism  \\\n",
       "0            False    False  False   True  False     False      False   \n",
       "1            False    False   True  False  False     False       True   \n",
       "2            False    False  False  False  False     False      False   \n",
       "3            False    False  False   True  False     False      False   \n",
       "4            False     True  False  False  False     False      False   \n",
       "...            ...      ...    ...    ...    ...       ...        ...   \n",
       "3556         False    False   True  False  False     False       True   \n",
       "3557         False     True  False  False  False     False      False   \n",
       "3558         False    False  False  False  False     False      False   \n",
       "3559         False    False  False   True  False     False      False   \n",
       "3560         False    False  False  False   True     False      False   \n",
       "\n",
       "      sadness  surprise  trust  \n",
       "0       False     False  False  \n",
       "1       False     False  False  \n",
       "2       False     False  False  \n",
       "3       False     False  False  \n",
       "4       False     False  False  \n",
       "...       ...       ...    ...  \n",
       "3556     True     False  False  \n",
       "3557    False     False  False  \n",
       "3558    False      True  False  \n",
       "3559    False     False  False  \n",
       "3560     True     False  False  \n",
       "\n",
       "[3397 rows x 13 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.select_dtypes(include='bool')\n",
    "for i in x.index: # filas\n",
    "    y = False\n",
    "    for j in ['anger','anticipation','disgust','fear','joy','love','optimism',\n",
    "              'pessimism','sadness','surprise','trust']: # Recorremos cada sentimiento\n",
    "        if x[j][i]:\n",
    "            y = True\n",
    "        elif not y:\n",
    "            if j == 'trust':\n",
    "                df = df.drop(i, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20145c",
   "metadata": {},
   "source": [
    "### Obtenemos los valores de los sentimientos y los guardamos en la variable categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ab4cd536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love',\n",
       "       'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories=x.columns.values\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebacbda",
   "metadata": {},
   "source": [
    "### Realizamos un recuento de las veces que sale cada sentimiento a modo informativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0f81bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 1155), ('anticipation', 415), ('disgust', 521), ('fear', 373), ('joy', 1087), ('love', 261), ('optimism', 378), ('pessimism', 578), ('sadness', 845), ('surprise', 169), ('trust', 175)]\n"
     ]
    }
   ],
   "source": [
    "count = list() # Esto es la lista con el recuento de cada sentimiento\n",
    "for i in ['anger','anticipation','disgust','fear','joy','love','optimism','pessimism','sadness','surprise','trust']: # Recorremos cada sentimiento\n",
    "    sum = 0\n",
    "    for j in df.index: # filas\n",
    "        if df[i][j]:\n",
    "            sum += 1\n",
    "    count.append((i,sum)) # Guardamos la suma\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283563c0",
   "metadata": {},
   "source": [
    "### Importamos todas las librer√≠as que nos pueden ser √∫tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dd39fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import resample\n",
    "\n",
    "import spacy\n",
    "\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation \n",
    "from gensim.models import LdaModel\n",
    "import gensim\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from textacy.extract import keyterms as kt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb050d2",
   "metadata": {},
   "source": [
    "### Creamos el modelo de limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d2f6b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de stop-words espec√≠ficos de nuestro corpus (aproximaci√≥n)\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "pattern2 = re.compile('[{}]'.format(re.escape(string.punctuation))) #elimina s√≠mbolos de puntuaci√≥n\n",
    "\n",
    "def clean_text(text, lemas=False):\n",
    "    \"\"\"Limpiamos las menciones y URL del texto. Luego convertimos en tokens\n",
    "    y eliminamos signos de puntuaci√≥n.\n",
    "    Si lemas=True extraemos el lema, si no dejamos en min√∫sculas solamente.\n",
    "    Como salida volvemos a convertir los tokens en cadena de texto\"\"\"\n",
    "    text = re.sub(r'@[\\w_]+|https?://[\\w_./]+', '', text) #elimina menciones y URL\n",
    "    tokens = nlp(text)\n",
    "    tokens = [tok.lemma_.lower() if lemas else tok.lower_ for tok in tokens if not tok.is_punct]\n",
    "    filtered_tokens = [pattern2.sub('', tok) for tok in tokens if len(tok)>2]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98660d",
   "metadata": {},
   "source": [
    "### Aplicamos la limpieza a los datos, lo hacemos con los Tweets limpios y con los lemas, y los a√±adimos a nuestro dataframe de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "571d8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"limpio\"]=df['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "94df1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemas\"]=df['Tweet'].apply(clean_text, lemas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee278f",
   "metadata": {},
   "source": [
    "### Seleccionamos las columnas referidas a sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "889ab7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3397 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger  anticipation  disgust   fear    joy   love  optimism  pessimism  \\\n",
       "0     False         False    False  False   True  False     False      False   \n",
       "1     False         False    False   True  False  False     False       True   \n",
       "2      True         False    False  False  False  False     False      False   \n",
       "3     False         False    False  False   True  False     False      False   \n",
       "4      True         False     True  False  False  False     False      False   \n",
       "...     ...           ...      ...    ...    ...    ...       ...        ...   \n",
       "3556  False         False    False   True  False  False     False       True   \n",
       "3557   True         False     True  False  False  False     False      False   \n",
       "3558   True         False    False  False  False  False     False      False   \n",
       "3559  False         False    False  False   True  False     False      False   \n",
       "3560  False         False    False  False  False   True     False      False   \n",
       "\n",
       "      sadness  surprise  trust  \n",
       "0       False     False  False  \n",
       "1       False     False  False  \n",
       "2       False     False  False  \n",
       "3       False     False  False  \n",
       "4       False     False  False  \n",
       "...       ...       ...    ...  \n",
       "3556     True     False  False  \n",
       "3557    False     False  False  \n",
       "3558    False      True  False  \n",
       "3559    False     False  False  \n",
       "3560     True     False  False  \n",
       "\n",
       "[3397 rows x 11 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.select_dtypes(include='bool')\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc517a0",
   "metadata": {},
   "source": [
    "### Dividimos los datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "156c1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "# Asignamos un 70% a training y un 30% a test\n",
    "X_train, X_test, y_train, y_test, X_train_lema, X_test_lema = train_test_split(df['limpio'], \n",
    "                                                    y,\n",
    "                                                    df['lemas'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efd5fb",
   "metadata": {},
   "source": [
    "### Extraemos las caracter√≠sticas mediante BoW, creamos los modelos, los entrenamos y realizamos las predicciones para comprarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9bc5cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2377, 6444)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# aprendemos el modelo CountVectorizer sobre el conjunto de train\n",
    "vect1 = CountVectorizer()\n",
    "\n",
    "X_train_vectorized1 = vect1.fit_transform(X_train)\n",
    "print(X_train_vectorized1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e0292c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                   solver='liblinear'))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODELO BOW - LR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "modelLR1 = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "model1 = MultiOutputClassifier(estimator=modelLR)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "model1.fit(X_train_vectorized1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "99042429",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_train = model1.predict(X_train_vectorized1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3da03ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.8754732856541859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Exactitud: ', accuracy_score(y_train, prediccion_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "91d3fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 6444)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectorized = vect1.transform(X_test)\n",
    "X_test_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a2f8f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = model1.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d46fbf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.18529411764705883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63       337\n",
      "           1       0.33      0.41      0.37       113\n",
      "           2       0.39      0.34      0.36       158\n",
      "           3       0.72      0.63      0.67       116\n",
      "           4       0.70      0.60      0.65       324\n",
      "           5       0.40      0.39      0.39        77\n",
      "           6       0.39      0.28      0.33       126\n",
      "           7       0.35      0.39      0.37       166\n",
      "           8       0.57      0.49      0.53       249\n",
      "           9       0.29      0.30      0.29        47\n",
      "          10       0.20      0.13      0.16        54\n",
      "\n",
      "   micro avg       0.52      0.48      0.50      1767\n",
      "   macro avg       0.45      0.42      0.43      1767\n",
      "weighted avg       0.52      0.48      0.50      1767\n",
      " samples avg       0.50      0.51      0.48      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e990a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.1450980392156863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.42      0.52       337\n",
      "           1       0.38      0.03      0.05       113\n",
      "           2       0.56      0.06      0.10       158\n",
      "           3       0.79      0.13      0.22       116\n",
      "           4       0.77      0.44      0.56       324\n",
      "           5       1.00      0.04      0.08        77\n",
      "           6       0.75      0.02      0.05       126\n",
      "           7       0.42      0.05      0.09       166\n",
      "           8       0.74      0.26      0.38       249\n",
      "           9       0.00      0.00      0.00        47\n",
      "          10       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.71      0.22      0.34      1767\n",
      "   macro avg       0.55      0.13      0.19      1767\n",
      "weighted avg       0.64      0.22      0.30      1767\n",
      " samples avg       0.34      0.26      0.28      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-NB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB=MultinomialNB()\n",
    "NB = MultiOutputClassifier(estimator=NB)\n",
    "#Entrenem el model\n",
    "NB.fit(X_train_vectorized1, y_train)\n",
    "\n",
    "#Realitzem les prediccions\n",
    "pred=NB.predict(X_test_vectorized)\n",
    "\n",
    "print('Exactitud: ', accuracy_score(y_test, pred))\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b444f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.15098039215686274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       337\n",
      "           1       0.24      0.47      0.32       113\n",
      "           2       0.35      0.32      0.33       158\n",
      "           3       0.67      0.57      0.62       116\n",
      "           4       0.65      0.60      0.62       324\n",
      "           5       0.36      0.42      0.38        77\n",
      "           6       0.37      0.24      0.29       126\n",
      "           7       0.27      0.30      0.29       166\n",
      "           8       0.53      0.45      0.48       249\n",
      "           9       0.24      0.36      0.29        47\n",
      "          10       0.22      0.15      0.18        54\n",
      "\n",
      "   micro avg       0.46      0.45      0.46      1767\n",
      "   macro avg       0.41      0.40      0.40      1767\n",
      "weighted avg       0.48      0.45      0.46      1767\n",
      " samples avg       0.45      0.48      0.43      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-SVM\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SVM=SGDClassifier(loss='hinge', max_iter=10000, tol=1e-5, class_weight='balanced')\n",
    "SVM = MultiOutputClassifier(estimator=SVM)\n",
    "\n",
    "#Entrenem el model\n",
    "SVM.fit(X_train_vectorized1, y_train)\n",
    "\n",
    "#Realitzem les prediccions\n",
    "pred=SVM.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a8a90",
   "metadata": {},
   "source": [
    "### Extraemos las caracter√≠sticas mediante TF-IDF, creamos los modelos, los entrenamos y realizamos las predicciones para comprarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3195c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.16666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64       337\n",
      "           1       0.29      0.44      0.35       113\n",
      "           2       0.33      0.39      0.36       158\n",
      "           3       0.69      0.61      0.65       116\n",
      "           4       0.68      0.64      0.66       324\n",
      "           5       0.37      0.40      0.39        77\n",
      "           6       0.34      0.33      0.34       126\n",
      "           7       0.34      0.49      0.40       166\n",
      "           8       0.53      0.53      0.53       249\n",
      "           9       0.31      0.32      0.31        47\n",
      "          10       0.20      0.17      0.18        54\n",
      "\n",
      "   micro avg       0.48      0.52      0.50      1767\n",
      "   macro avg       0.43      0.45      0.44      1767\n",
      "weighted avg       0.50      0.52      0.51      1767\n",
      " samples avg       0.49      0.55      0.49      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "modelo = make_pipeline(vect, model)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6eb481b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.04803921568627451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.12      0.21       337\n",
      "           1       0.00      0.00      0.00       113\n",
      "           2       0.00      0.00      0.00       158\n",
      "           3       0.00      0.00      0.00       116\n",
      "           4       0.95      0.13      0.22       324\n",
      "           5       0.00      0.00      0.00        77\n",
      "           6       0.00      0.00      0.00       126\n",
      "           7       0.00      0.00      0.00       166\n",
      "           8       0.92      0.04      0.08       249\n",
      "           9       0.00      0.00      0.00        47\n",
      "          10       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.88      0.05      0.10      1767\n",
      "   macro avg       0.24      0.03      0.05      1767\n",
      "weighted avg       0.46      0.05      0.09      1767\n",
      " samples avg       0.09      0.07      0.08      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = make_pipeline(vect, NB)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7f007ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.1676470588235294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61       337\n",
      "           1       0.33      0.39      0.36       113\n",
      "           2       0.33      0.33      0.33       158\n",
      "           3       0.68      0.60      0.64       116\n",
      "           4       0.67      0.60      0.64       324\n",
      "           5       0.37      0.38      0.37        77\n",
      "           6       0.29      0.20      0.24       126\n",
      "           7       0.32      0.36      0.34       166\n",
      "           8       0.51      0.49      0.50       249\n",
      "           9       0.31      0.34      0.32        47\n",
      "          10       0.22      0.13      0.16        54\n",
      "\n",
      "   micro avg       0.49      0.47      0.48      1767\n",
      "   macro avg       0.42      0.40      0.41      1767\n",
      "weighted avg       0.49      0.47      0.48      1767\n",
      " samples avg       0.48      0.50      0.46      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = make_pipeline(vect, SVM)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fded011",
   "metadata": {},
   "source": [
    "### Hacemos los mismo pero con los lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7224170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2377, 5337)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizamos\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train_lema)\n",
    "X_test_vectorized = vect.transform(X_test_lema)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "98d88b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.1715686274509804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60       337\n",
      "           1       0.32      0.40      0.35       113\n",
      "           2       0.33      0.32      0.33       158\n",
      "           3       0.70      0.62      0.66       116\n",
      "           4       0.69      0.63      0.66       324\n",
      "           5       0.43      0.43      0.43        77\n",
      "           6       0.38      0.31      0.34       126\n",
      "           7       0.33      0.42      0.37       166\n",
      "           8       0.55      0.51      0.53       249\n",
      "           9       0.23      0.28      0.25        47\n",
      "          10       0.20      0.17      0.18        54\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      1767\n",
      "   macro avg       0.43      0.43      0.43      1767\n",
      "weighted avg       0.51      0.49      0.50      1767\n",
      " samples avg       0.48      0.51      0.46      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-LR\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "prediccion = model.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a634b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.1411764705882353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.41      0.52       337\n",
      "           1       0.50      0.02      0.03       113\n",
      "           2       0.58      0.07      0.12       158\n",
      "           3       0.73      0.09      0.17       116\n",
      "           4       0.79      0.36      0.50       324\n",
      "           5       1.00      0.06      0.12        77\n",
      "           6       0.50      0.01      0.02       126\n",
      "           7       0.39      0.04      0.08       166\n",
      "           8       0.72      0.22      0.34       249\n",
      "           9       0.00      0.00      0.00        47\n",
      "          10       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.72      0.20      0.31      1767\n",
      "   macro avg       0.54      0.12      0.17      1767\n",
      "weighted avg       0.63      0.20      0.28      1767\n",
      " samples avg       0.31      0.24      0.26      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-NB\n",
    "NB.fit(X_train_vectorized, y_train)\n",
    "prediccion = NB.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81835507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.14411764705882352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       337\n",
      "           1       0.27      0.35      0.30       113\n",
      "           2       0.27      0.38      0.32       158\n",
      "           3       0.67      0.55      0.61       116\n",
      "           4       0.66      0.59      0.62       324\n",
      "           5       0.38      0.29      0.33        77\n",
      "           6       0.32      0.32      0.32       126\n",
      "           7       0.32      0.43      0.36       166\n",
      "           8       0.47      0.56      0.51       249\n",
      "           9       0.17      0.26      0.20        47\n",
      "          10       0.17      0.13      0.15        54\n",
      "\n",
      "   micro avg       0.44      0.48      0.46      1767\n",
      "   macro avg       0.39      0.40      0.39      1767\n",
      "weighted avg       0.46      0.48      0.47      1767\n",
      " samples avg       0.44      0.50      0.44      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo BoW-SVM\n",
    "SVM.fit(X_train_vectorized, y_train)\n",
    "prediccion = SVM.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f942376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2377, 5337)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizamos\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train_lema)\n",
    "X_test_vectorized = vect.transform(X_test_lema)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5536a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.15588235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.61       337\n",
      "           1       0.27      0.46      0.34       113\n",
      "           2       0.30      0.42      0.35       158\n",
      "           3       0.67      0.65      0.66       116\n",
      "           4       0.67      0.65      0.66       324\n",
      "           5       0.36      0.45      0.40        77\n",
      "           6       0.32      0.37      0.34       126\n",
      "           7       0.30      0.50      0.37       166\n",
      "           8       0.50      0.55      0.52       249\n",
      "           9       0.21      0.32      0.25        47\n",
      "          10       0.16      0.17      0.16        54\n",
      "\n",
      "   micro avg       0.44      0.53      0.48      1767\n",
      "   macro avg       0.39      0.47      0.43      1767\n",
      "weighted avg       0.47      0.53      0.50      1767\n",
      " samples avg       0.46      0.56      0.47      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo TFIDF-LR\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "prediccion = model.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d1a76c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.054901960784313725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.13      0.23       337\n",
      "           1       1.00      0.01      0.02       113\n",
      "           2       0.00      0.00      0.00       158\n",
      "           3       0.00      0.00      0.00       116\n",
      "           4       0.96      0.14      0.25       324\n",
      "           5       0.00      0.00      0.00        77\n",
      "           6       0.00      0.00      0.00       126\n",
      "           7       0.00      0.00      0.00       166\n",
      "           8       1.00      0.04      0.08       249\n",
      "           9       0.00      0.00      0.00        47\n",
      "          10       0.00      0.00      0.00        54\n",
      "\n",
      "   micro avg       0.91      0.06      0.11      1767\n",
      "   macro avg       0.35      0.03      0.05      1767\n",
      "weighted avg       0.54      0.06      0.10      1767\n",
      " samples avg       0.10      0.08      0.08      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo TFIDF-NB\n",
    "NB.fit(X_train_vectorized, y_train)\n",
    "prediccion = NB.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9231f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud:  0.15588235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59       337\n",
      "           1       0.27      0.32      0.29       113\n",
      "           2       0.29      0.32      0.31       158\n",
      "           3       0.63      0.55      0.59       116\n",
      "           4       0.66      0.61      0.63       324\n",
      "           5       0.45      0.38      0.41        77\n",
      "           6       0.31      0.28      0.29       126\n",
      "           7       0.30      0.39      0.34       166\n",
      "           8       0.50      0.51      0.51       249\n",
      "           9       0.17      0.19      0.18        47\n",
      "          10       0.20      0.15      0.17        54\n",
      "\n",
      "   micro avg       0.46      0.47      0.46      1767\n",
      "   macro avg       0.40      0.39      0.39      1767\n",
      "weighted avg       0.47      0.47      0.46      1767\n",
      " samples avg       0.45      0.49      0.44      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo TFIDF-SVM\n",
    "SVM.fit(X_train_vectorized, y_train)\n",
    "prediccion = SVM.predict(X_test_vectorized)\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13480e50",
   "metadata": {},
   "source": [
    "### Una vez realizados todos los modelos y comparando su accuracy y sus tablas, decidimos que el mejor modelo entrenado es el LogisticRegression extrayendo las caracter√≠sticas mediante BoW, por lo que vamos a realizar la predicci√≥n de los datos de test mediante este modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58762a1",
   "metadata": {},
   "source": [
    "### Limpiamos los Tweets del dataframe de test proporcionado para, a continuaci√≥n, realizar la predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9d539981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      jaj tan resentido\n",
       "1                                estoy emocionada aaaaah\n",
       "2                        satisfacci√≥n por deber cumplido\n",
       "3                considerate afortunada m√≠o hasta ignora\n",
       "4                                                  enojo\n",
       "                             ...                        \n",
       "674                 que nunca vas dejar ponerme nerviosa\n",
       "675                    anon sos terrible cornuda bla etc\n",
       "676           problemas trabajo embarque detenido terror\n",
       "677    nostalgia unas horas lanzamiento oficial secue...\n",
       "678                    anoche estall√≥ vena furia milagro\n",
       "Name: Tweet, Length: 679, dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet=df2['Tweet']\n",
    "limpio=tweet.apply(clean_text)\n",
    "limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1035e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "limpio_vec=vect1.transform(limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8bbe20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(679, 6444)\n",
      "(2377, 6444)\n"
     ]
    }
   ],
   "source": [
    "print(limpio_vec.shape)\n",
    "print(X_train_vectorized1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ca62fae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False,  True],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       [ True, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modelo BoW-LR\n",
    "\n",
    "#Realitzem les prediccions\n",
    "pred=model1.predict(limpio_vec)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "22235615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Es-00074</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Es-02721</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Es-04447</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Es-04392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Es-03765</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2018-Es-00162</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2018-Es-05538</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2018-Es-00430</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2018-Es-02679</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2018-Es-06005</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  anger  anticipation  disgust   fear    joy   love  \\\n",
       "0    2018-Es-00074   True         False     True  False  False  False   \n",
       "1    2018-Es-02721  False         False    False  False   True  False   \n",
       "2    2018-Es-04447  False         False    False  False   True  False   \n",
       "3    2018-Es-04392  False         False    False  False   True  False   \n",
       "4    2018-Es-03765   True          True    False  False  False  False   \n",
       "..             ...    ...           ...      ...    ...    ...    ...   \n",
       "674  2018-Es-00162  False          True    False   True  False  False   \n",
       "675  2018-Es-05538   True         False     True  False  False  False   \n",
       "676  2018-Es-00430  False         False    False   True  False  False   \n",
       "677  2018-Es-02679  False         False    False  False  False  False   \n",
       "678  2018-Es-06005   True         False    False  False  False  False   \n",
       "\n",
       "     optimism  pessimism  sadness  surprise  trust  \n",
       "0       False      False    False     False  False  \n",
       "1       False      False    False     False  False  \n",
       "2       False      False    False     False   True  \n",
       "3       False      False    False     False   True  \n",
       "4       False      False    False     False  False  \n",
       "..        ...        ...      ...       ...    ...  \n",
       "674     False      False    False     False  False  \n",
       "675     False      False    False     False  False  \n",
       "676     False      False    False     False  False  \n",
       "677     False      False     True     False  False  \n",
       "678     False      False    False     False  False  \n",
       "\n",
       "[679 rows x 12 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitivo=pd.concat([df2['ID'], pd.DataFrame(pred,columns=categories)], axis=1)\n",
    "definitivo.iloc[:,1:]=definitivo.iloc[:,1:]==1\n",
    "definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7cc14d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 679 entries, 0 to 678\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ID            679 non-null    object\n",
      " 1   anger         679 non-null    bool  \n",
      " 2   anticipation  679 non-null    bool  \n",
      " 3   disgust       679 non-null    bool  \n",
      " 4   fear          679 non-null    bool  \n",
      " 5   joy           679 non-null    bool  \n",
      " 6   love          679 non-null    bool  \n",
      " 7   optimism      679 non-null    bool  \n",
      " 8   pessimism     679 non-null    bool  \n",
      " 9   sadness       679 non-null    bool  \n",
      " 10  surprise      679 non-null    bool  \n",
      " 11  trust         679 non-null    bool  \n",
      "dtypes: bool(11), object(1)\n",
      "memory usage: 12.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Juntamos los dataframes para obtener el definitivo\n",
    "definitivo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b5630",
   "metadata": {},
   "source": [
    "### Creamos el csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "174b4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitivo.to_csv('grupo11.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
